{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for One-Dimensional Random Walk:\n",
      "\n",
      "For p = 0.5:\n",
      "Theoretical mean: 0.00\n",
      "Experimental mean: 1.82\n",
      "Mean error: 1.82%\n",
      "Theoretical variance: 1000.00\n",
      "Experimental variance: 1040.47\n",
      "Variance error: 4.05%\n",
      "\n",
      "For p = 0.7:\n",
      "Theoretical mean: 400.00\n",
      "Experimental mean: 400.50\n",
      "Mean error: 0.13%\n",
      "Theoretical variance: 840.00\n",
      "Experimental variance: 915.05\n",
      "Variance error: 8.93%\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def one_dimensional_random_walk(num_steps, p=0.5, step_length=1.0):\n",
    "    position = 0.0\n",
    "    trajectory = np.zeros(num_steps + 1)\n",
    "    trajectory[0] = position\n",
    "    \n",
    "    for i in range(1, num_steps + 1):\n",
    "        if np.random.random() < p:\n",
    "            position += step_length\n",
    "        else:\n",
    "            position -= step_length\n",
    "        \n",
    "        trajectory[i] = position\n",
    "    \n",
    "    return position, trajectory\n",
    "\n",
    "def verify_theoretical_relations(num_walks=1000, num_steps=1000, p_values=[0.5, 0.7]):\n",
    "    results = {}\n",
    "    step_length = 1.0\n",
    "    \n",
    "    for p in p_values:\n",
    "        q = 1.0 - p\n",
    "        \n",
    "        theoretical_mean = (p - q) * step_length * num_steps\n",
    "        theoretical_variance = 4 * step_length**2 * p * q * num_steps\n",
    "        \n",
    "        final_positions = np.zeros(num_walks)\n",
    "        for i in range(num_walks):\n",
    "            final_position, _ = one_dimensional_random_walk(num_steps, p, step_length)\n",
    "            final_positions[i] = final_position\n",
    "        \n",
    "        experimental_mean = np.mean(final_positions)\n",
    "        experimental_variance = np.var(final_positions)\n",
    "        \n",
    "        results[p] = {\n",
    "            'theoretical_mean': theoretical_mean,\n",
    "            'experimental_mean': experimental_mean,\n",
    "            'mean_error': abs(theoretical_mean - experimental_mean) / abs(theoretical_mean) * 100 if theoretical_mean != 0 else abs(experimental_mean),\n",
    "            'theoretical_variance': theoretical_variance,\n",
    "            'experimental_variance': experimental_variance,\n",
    "            'variance_error': abs(theoretical_variance - experimental_variance) / theoretical_variance * 100\n",
    "        }\n",
    "    \n",
    "    return results\n",
    "\n",
    "def plot_random_walk_examples(num_steps=1000, p_values=[0.5, 0.7]):\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    \n",
    "    for p in p_values:\n",
    "        _, trajectory = one_dimensional_random_walk(num_steps, p)\n",
    "        plt.plot(range(num_steps + 1), trajectory, label=f'p = {p}')\n",
    "    \n",
    "    plt.xlabel('Steps')\n",
    "    plt.ylabel('Position')\n",
    "    plt.title('Example Random Walk Trajectories')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.savefig('random_walk_trajectories.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "def demonstrate_central_limit_theorem(num_walks=10000, num_steps=1000, p=0.5):\n",
    "    final_positions = np.zeros(num_walks)\n",
    "    \n",
    "    for i in range(num_walks):\n",
    "        final_position, _ = one_dimensional_random_walk(num_steps, p)\n",
    "        final_positions[i] = final_position\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    \n",
    "    plt.hist(final_positions, bins=50, density=True, alpha=0.7, label='Simulation')\n",
    "    \n",
    "    x = np.linspace(min(final_positions), max(final_positions), 1000)\n",
    "    theoretical_mean = (p - (1-p)) * num_steps\n",
    "    theoretical_variance = 4 * p * (1-p) * num_steps\n",
    "    gaussian = 1/np.sqrt(2*np.pi*theoretical_variance) * np.exp(-(x-theoretical_mean)**2/(2*theoretical_variance))\n",
    "    plt.plot(x, gaussian, 'r-', label='Theoretical Gaussian')\n",
    "    \n",
    "    plt.xlabel('Final Position')\n",
    "    plt.ylabel('Probability Density')\n",
    "    plt.title('Distribution of Final Positions after Random Walks')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.savefig('random_walk_distribution.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "\n",
    "results = verify_theoretical_relations()\n",
    "\n",
    "print(\"Results for One-Dimensional Random Walk:\")\n",
    "for p, result in results.items():\n",
    "    print(f\"\\nFor p = {p}:\")\n",
    "    print(f\"Theoretical mean: {result['theoretical_mean']:.2f}\")\n",
    "    print(f\"Experimental mean: {result['experimental_mean']:.2f}\")\n",
    "    print(f\"Mean error: {result['mean_error']:.2f}%\")\n",
    "    print(f\"Theoretical variance: {result['theoretical_variance']:.2f}\")\n",
    "    print(f\"Experimental variance: {result['experimental_variance']:.2f}\")\n",
    "    print(f\"Variance error: {result['variance_error']:.2f}%\")\n",
    "\n",
    "plot_random_walk_examples()\n",
    "\n",
    "demonstrate_central_limit_theorem()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_walk_with_traps(x0, trap_positions, max_steps=1000000):\n",
    "    position = x0\n",
    "    steps = 0\n",
    "    \n",
    "    while position not in trap_positions and steps < max_steps:\n",
    "        if np.random.random() < 0.5:\n",
    "            position += 1\n",
    "        else:\n",
    "            position -= 1\n",
    "        \n",
    "        steps += 1\n",
    "    \n",
    "    return steps, position\n",
    "\n",
    "def calculate_average_lifetime(x0, trap_positions, num_walks=10000):\n",
    "    lifetimes = np.zeros(num_walks)\n",
    "    final_positions = np.zeros(num_walks)\n",
    "    \n",
    "    for i in range(num_walks):\n",
    "        lifetime, final_position = random_walk_with_traps(x0, trap_positions)\n",
    "        lifetimes[i] = lifetime\n",
    "        final_positions[i] = final_position\n",
    "    \n",
    "    average_lifetime = np.mean(lifetimes)\n",
    "    standard_error = np.std(lifetimes) / np.sqrt(num_walks)\n",
    "    \n",
    "    trap_stats = {}\n",
    "    for trap in trap_positions:\n",
    "        trap_stats[trap] = np.sum(final_positions == trap) / num_walks\n",
    "    \n",
    "    return average_lifetime, standard_error, trap_stats\n",
    "\n",
    "def calculate_average_lifetime_enumeration(trap_positions, lattice_size=21):\n",
    "    average_lifetimes = np.zeros(lattice_size)\n",
    "    left_trap_probs = np.zeros(lattice_size)\n",
    "    right_trap_probs = np.zeros(lattice_size)\n",
    "    \n",
    "    for trap in trap_positions:\n",
    "        average_lifetimes[trap] = 0\n",
    "        \n",
    "        if trap == trap_positions[0]:\n",
    "            left_trap_probs[trap] = 1.0\n",
    "            right_trap_probs[trap] = 0.0\n",
    "        else:\n",
    "            left_trap_probs[trap] = 0.0\n",
    "            right_trap_probs[trap] = 1.0\n",
    "    \n",
    "    non_trap_indices = [i for i in range(lattice_size) if i not in trap_positions]\n",
    "    \n",
    "    max_iterations = 10000\n",
    "    tolerance = 1e-10\n",
    "    \n",
    "    for x in non_trap_indices:\n",
    "        left_trap_probs[x] = 1.0 - (x - trap_positions[0]) / (trap_positions[1] - trap_positions[0])\n",
    "        right_trap_probs[x] = 1.0 - left_trap_probs[x]\n",
    "        average_lifetimes[x] = x * (lattice_size - 1 - x)\n",
    "    \n",
    "    for _ in range(max_iterations):\n",
    "        max_change = 0\n",
    "        for x in non_trap_indices:\n",
    "            old_value = left_trap_probs[x]\n",
    "            left_trap_probs[x] = 0.5 * (left_trap_probs[max(0, x-1)] + left_trap_probs[min(lattice_size-1, x+1)])\n",
    "            max_change = max(max_change, abs(left_trap_probs[x] - old_value))\n",
    "        \n",
    "        if max_change < tolerance:\n",
    "            break\n",
    "    \n",
    "    for x in non_trap_indices:\n",
    "        right_trap_probs[x] = 1.0 - left_trap_probs[x]\n",
    "    \n",
    "    for _ in range(max_iterations):\n",
    "        max_change = 0\n",
    "        for x in non_trap_indices:\n",
    "            old_value = average_lifetimes[x]\n",
    "            average_lifetimes[x] = 1 + 0.5 * (average_lifetimes[max(0, x-1)] + average_lifetimes[min(lattice_size-1, x+1)])\n",
    "            max_change = max(max_change, abs(average_lifetimes[x] - old_value))\n",
    "        \n",
    "        if max_change < tolerance:\n",
    "            break\n",
    "    \n",
    "    return average_lifetimes, left_trap_probs, right_trap_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def analytical_lifetime(x, L):\n",
    "    return x * (L - x)\n",
    "\n",
    "def analytical_left_prob(x, L):\n",
    "    return (L - x) / L\n",
    "\n",
    "def analytical_right_prob(x, L):\n",
    "    return x / L\n",
    "\n",
    "def generate_comparison_figure():\n",
    "    lattice_size = 21\n",
    "    center = lattice_size // 2\n",
    "    trap_positions = [center - 10, center + 10]\n",
    "    initial_positions = range(1, lattice_size - 1)\n",
    "\n",
    "    mc_lifetimes = []\n",
    "    mc_errors = []\n",
    "    mc_left_probs = []\n",
    "    mc_right_probs = []\n",
    "    for x0 in initial_positions:\n",
    "        avg_lt, err, stats = calculate_average_lifetime(x0, trap_positions, num_walks=10000)\n",
    "        mc_lifetimes.append(avg_lt)\n",
    "        mc_errors.append(err)\n",
    "        mc_left_probs.append(stats[trap_positions[0]])\n",
    "        mc_right_probs.append(stats[trap_positions[1]])\n",
    "\n",
    "    enum_lifetimes, enum_left_probs, enum_right_probs = calculate_average_lifetime_enumeration(trap_positions, lattice_size)\n",
    "\n",
    "    ana_lifetimes = [analytical_lifetime(x, lattice_size - 1) for x in initial_positions]\n",
    "    ana_left_probs = [analytical_left_prob(x, lattice_size - 1) for x in initial_positions]\n",
    "    ana_right_probs = [analytical_right_prob(x, lattice_size - 1) for x in initial_positions]\n",
    "\n",
    "    mc_rel_error = [abs(mc - ana) / ana * 100 for mc, ana in zip(mc_lifetimes, ana_lifetimes)]\n",
    "    enum_rel_error = [abs(enum - ana) / ana * 100 for enum, ana in zip(enum_lifetimes[1:-1], ana_lifetimes)]\n",
    "\n",
    "    plt.figure(figsize=(10, 12))\n",
    "\n",
    "    plt.subplot(3, 1, 1)\n",
    "    plt.errorbar(initial_positions, mc_lifetimes, yerr=mc_errors, fmt='bo-', label='Monte Carlo')\n",
    "    plt.plot(initial_positions, enum_lifetimes[1:-1], 'r^-', label='Enumeration')\n",
    "    plt.plot(initial_positions, ana_lifetimes, 'g--', label='Analytical')\n",
    "    plt.xlabel('Initial Position')\n",
    "    plt.ylabel('Average Lifetime')\n",
    "    plt.title('Average Lifetime vs Initial Position')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "\n",
    "    plt.subplot(3, 1, 2)\n",
    "    plt.plot(initial_positions, mc_left_probs, 'bo-', label='Monte Carlo (Left)')\n",
    "    plt.plot(initial_positions, enum_left_probs[1:-1], 'b^-', label='Enumeration (Left)')\n",
    "    plt.plot(initial_positions, ana_left_probs, 'b--', label='Analytical (Left)')\n",
    "    plt.plot(initial_positions, mc_right_probs, 'ro-', label='Monte Carlo (Right)')\n",
    "    plt.plot(initial_positions, enum_right_probs[1:-1], 'r^-', label='Enumeration (Right)')\n",
    "    plt.plot(initial_positions, ana_right_probs, 'r--', label='Analytical (Right)')\n",
    "    plt.xlabel('Initial Position')\n",
    "    plt.ylabel('Absorption Probability')\n",
    "    plt.title('Probability of Absorption at Left and Right Boundaries')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "\n",
    "    plt.subplot(3, 1, 3)\n",
    "    plt.plot(initial_positions, mc_rel_error, 'bo-', label='Monte Carlo')\n",
    "    plt.plot(initial_positions, enum_rel_error, 'r^-', label='Enumeration')\n",
    "    plt.xlabel('Initial Position')\n",
    "    plt.ylabel('Relative Error (%)')\n",
    "    plt.title('Relative Error Compared to Analytical Solution (Lifetime)')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('trap_problem_comparison.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "def generate_performance_figure():\n",
    "    lattice_size = 21\n",
    "    trap_positions = [0, 20]\n",
    "    initial_position = 10\n",
    "    num_walks_list = [100, 1000, 10000, 100000]\n",
    "\n",
    "    mc_times = []\n",
    "    for num_walks in num_walks_list:\n",
    "        start_time = time.time()\n",
    "        calculate_average_lifetime(initial_position, trap_positions, num_walks)\n",
    "        mc_times.append(time.time() - start_time)\n",
    "\n",
    "    start_time = time.time()\n",
    "    calculate_average_lifetime_enumeration(trap_positions, lattice_size)\n",
    "    enum_time = time.time() - start_time\n",
    "\n",
    "    ana_time = 0.0001\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.semilogy(num_walks_list, mc_times, 'bo-', label='Monte Carlo')\n",
    "    plt.axhline(y=enum_time, color='r', linestyle='--', label='Enumeration')\n",
    "    plt.axhline(y=ana_time, color='g', linestyle='-.', label='Analytical')\n",
    "    plt.xlabel('Number of Monte Carlo Simulations')\n",
    "    plt.ylabel('Execution Time (s)')\n",
    "    plt.title('Performance Comparison (Log Scale)')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.savefig('trap_problem_performance.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "generate_comparison_figure()\n",
    "generate_performance_figure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial position 1: Average lifetime = 19.19 ± 0.48\n",
      "  Probability of being trapped at position 0: 0.9471\n",
      "  Probability of being trapped at position 20: 0.0529\n",
      "Initial position 2: Average lifetime = 36.46 ± 0.64\n",
      "  Probability of being trapped at position 0: 0.9014\n",
      "  Probability of being trapped at position 20: 0.0986\n",
      "Initial position 3: Average lifetime = 50.61 ± 0.70\n",
      "  Probability of being trapped at position 0: 0.8524\n",
      "  Probability of being trapped at position 20: 0.1476\n",
      "Initial position 4: Average lifetime = 63.89 ± 0.77\n",
      "  Probability of being trapped at position 0: 0.7991\n",
      "  Probability of being trapped at position 20: 0.2009\n",
      "Initial position 5: Average lifetime = 75.72 ± 0.79\n",
      "  Probability of being trapped at position 0: 0.7498\n",
      "  Probability of being trapped at position 20: 0.2502\n",
      "Initial position 6: Average lifetime = 82.76 ± 0.81\n",
      "  Probability of being trapped at position 0: 0.7005\n",
      "  Probability of being trapped at position 20: 0.2995\n",
      "Initial position 7: Average lifetime = 91.35 ± 0.81\n",
      "  Probability of being trapped at position 0: 0.6516\n",
      "  Probability of being trapped at position 20: 0.3484\n",
      "Initial position 8: Average lifetime = 96.33 ± 0.80\n",
      "  Probability of being trapped at position 0: 0.6015\n",
      "  Probability of being trapped at position 20: 0.3985\n",
      "Initial position 9: Average lifetime = 99.35 ± 0.83\n",
      "  Probability of being trapped at position 0: 0.5420\n",
      "  Probability of being trapped at position 20: 0.4580\n",
      "Initial position 10: Average lifetime = 99.98 ± 0.82\n",
      "  Probability of being trapped at position 0: 0.5043\n",
      "  Probability of being trapped at position 20: 0.4957\n",
      "Initial position 11: Average lifetime = 101.39 ± 0.85\n",
      "  Probability of being trapped at position 0: 0.4508\n",
      "  Probability of being trapped at position 20: 0.5492\n",
      "Initial position 12: Average lifetime = 95.10 ± 0.80\n",
      "  Probability of being trapped at position 0: 0.3964\n",
      "  Probability of being trapped at position 20: 0.6036\n",
      "Initial position 13: Average lifetime = 90.29 ± 0.82\n",
      "  Probability of being trapped at position 0: 0.3441\n",
      "  Probability of being trapped at position 20: 0.6559\n",
      "Initial position 14: Average lifetime = 83.32 ± 0.80\n",
      "  Probability of being trapped at position 0: 0.2975\n",
      "  Probability of being trapped at position 20: 0.7025\n",
      "Initial position 15: Average lifetime = 76.27 ± 0.79\n",
      "  Probability of being trapped at position 0: 0.2498\n",
      "  Probability of being trapped at position 20: 0.7502\n",
      "Initial position 16: Average lifetime = 64.59 ± 0.76\n",
      "  Probability of being trapped at position 0: 0.2025\n",
      "  Probability of being trapped at position 20: 0.7975\n",
      "Initial position 17: Average lifetime = 51.16 ± 0.72\n",
      "  Probability of being trapped at position 0: 0.1453\n",
      "  Probability of being trapped at position 20: 0.8547\n",
      "Initial position 18: Average lifetime = 36.79 ± 0.65\n",
      "  Probability of being trapped at position 0: 0.1041\n",
      "  Probability of being trapped at position 20: 0.8959\n",
      "Initial position 19: Average lifetime = 19.29 ± 0.48\n",
      "  Probability of being trapped at position 0: 0.0525\n",
      "  Probability of being trapped at position 20: 0.9475\n"
     ]
    }
   ],
   "source": [
    "def random_walk_with_traps(x0, trap_positions, max_steps=1000000):\n",
    "    position = x0\n",
    "    steps = 0\n",
    "    \n",
    "    while position not in trap_positions and steps < max_steps:\n",
    "        if np.random.random() < 0.5:\n",
    "            position += 1\n",
    "        else:\n",
    "            position -= 1\n",
    "        \n",
    "        steps += 1\n",
    "    \n",
    "    return steps, position\n",
    "\n",
    "def calculate_average_lifetime(x0, trap_positions, num_walks=10000):\n",
    "    lifetimes = np.zeros(num_walks)\n",
    "    final_positions = np.zeros(num_walks)\n",
    "    \n",
    "    for i in range(num_walks):\n",
    "        lifetime, final_position = random_walk_with_traps(x0, trap_positions)\n",
    "        lifetimes[i] = lifetime\n",
    "        final_positions[i] = final_position\n",
    "    \n",
    "    average_lifetime = np.mean(lifetimes)\n",
    "    standard_error = np.std(lifetimes) / np.sqrt(num_walks)\n",
    "    \n",
    "    trap_stats = {}\n",
    "    for trap in trap_positions:\n",
    "        trap_stats[trap] = np.sum(final_positions == trap) / num_walks\n",
    "    \n",
    "    return average_lifetime, standard_error, trap_stats\n",
    "\n",
    "def analyze_trap_problem():\n",
    "    lattice_size = 21\n",
    "    center = lattice_size // 2\n",
    "    trap_positions = [center - 10, center + 10]\n",
    "    \n",
    "    initial_positions = range(1, lattice_size - 1)\n",
    "    lifetimes = []\n",
    "    errors = []\n",
    "    left_trap_probs = []\n",
    "    right_trap_probs = []\n",
    "    \n",
    "    for x0 in initial_positions:\n",
    "        avg_lifetime, error, trap_stats = calculate_average_lifetime(x0, trap_positions)\n",
    "        lifetimes.append(avg_lifetime)\n",
    "        errors.append(error)\n",
    "        left_trap_probs.append(trap_stats.get(trap_positions[0], 0))\n",
    "        right_trap_probs.append(trap_stats.get(trap_positions[1], 0))\n",
    "        \n",
    "        print(f\"Initial position {x0}: Average lifetime = {avg_lifetime:.2f} ± {error:.2f}\")\n",
    "        for trap, prob in trap_stats.items():\n",
    "            print(f\"  Probability of being trapped at position {trap}: {prob:.4f}\")\n",
    "    \n",
    "    plt.figure(figsize=(12, 8))\n",
    "    \n",
    "    plt.subplot(2, 1, 1)\n",
    "    plt.errorbar(initial_positions, lifetimes, yerr=errors, fmt='o-', capsize=3)\n",
    "    plt.xlabel('Initial Position')\n",
    "    plt.ylabel('Average Lifetime')\n",
    "    plt.title('Average Lifetime of Random Walker Before Absorption')\n",
    "    plt.grid(True)\n",
    "    \n",
    "    plt.subplot(2, 1, 2)\n",
    "    plt.plot(initial_positions, left_trap_probs, 'bo-', label=f'Trap at {trap_positions[0]}')\n",
    "    plt.plot(initial_positions, right_trap_probs, 'ro-', label=f'Trap at {trap_positions[1]}')\n",
    "    plt.xlabel('Initial Position')\n",
    "    plt.ylabel('Probability of Absorption')\n",
    "    plt.title('Probability of Being Absorbed by Each Trap')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('trap_problem_analysis.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "analyze_trap_problem()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/km/y1gjflc56rd069hf7r__rftc0000gn/T/ipykernel_4028/2336296439.py:85: RuntimeWarning: invalid value encountered in divide\n",
      "  relative_error = np.abs(msd - theoretical_msd) / theoretical_msd * 100\n"
     ]
    }
   ],
   "source": [
    "def two_dimensional_random_walk(num_steps):\n",
    "    x, y = 0, 0\n",
    "    x_trajectory = np.zeros(num_steps + 1)\n",
    "    y_trajectory = np.zeros(num_steps + 1)\n",
    "    x_trajectory[0] = x\n",
    "    y_trajectory[0] = y\n",
    "    \n",
    "    for i in range(1, num_steps + 1):\n",
    "        direction = np.random.random()\n",
    "        \n",
    "        if direction < 0.25:\n",
    "            x += 1\n",
    "        elif direction < 0.5:\n",
    "            x -= 1\n",
    "        elif direction < 0.75:\n",
    "            y += 1\n",
    "        else:\n",
    "            y -= 1\n",
    "        \n",
    "        x_trajectory[i] = x\n",
    "        y_trajectory[i] = y\n",
    "    \n",
    "    return (x, y), x_trajectory, y_trajectory\n",
    "\n",
    "def calculate_mean_squared_displacement(num_walks=1000, num_steps=1000, step_interval=10):\n",
    "    time_points = np.arange(0, num_steps + 1, step_interval)\n",
    "    num_measurements = len(time_points)\n",
    "    \n",
    "    squared_displacements = np.zeros((num_walks, num_measurements))\n",
    "    \n",
    "    for i in range(num_walks):\n",
    "        _, x_traj, y_traj = two_dimensional_random_walk(num_steps)\n",
    "        \n",
    "        for j, t in enumerate(time_points):\n",
    "            squared_displacements[i, j] = x_traj[t]**2 + y_traj[t]**2\n",
    "    \n",
    "    mean_squared_displacement = np.mean(squared_displacements, axis=0)\n",
    "    std_error = np.std(squared_displacements, axis=0) / np.sqrt(num_walks)\n",
    "    \n",
    "    return time_points, mean_squared_displacement, std_error\n",
    "\n",
    "def verify_scaling_law():\n",
    "    time_points, msd, error = calculate_mean_squared_displacement()\n",
    "    \n",
    "    D = 0.25\n",
    "    theoretical_msd = 4 * D * time_points\n",
    "    \n",
    "    relative_error = np.abs(msd - theoretical_msd) / theoretical_msd * 100\n",
    "    \n",
    "    plt.figure(figsize=(12, 8))\n",
    "    \n",
    "    plt.subplot(2, 1, 1)\n",
    "    plt.errorbar(time_points, msd, yerr=error, fmt='o', capsize=3, label='Simulation')\n",
    "    plt.plot(time_points, theoretical_msd, 'r-', label='Theory: $\\\\langle r^2 \\\\rangle = 4Dt$')\n",
    "    plt.xlabel('Time Steps')\n",
    "    plt.ylabel('Mean Squared Displacement')\n",
    "    plt.title('Mean Squared Displacement for 2D Random Walk')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    \n",
    "    plt.subplot(2, 1, 2)\n",
    "    plt.plot(time_points[1:], relative_error[1:], 'bo-')\n",
    "    plt.xlabel('Time Steps')\n",
    "    plt.ylabel('Relative Error (%)')\n",
    "    plt.title('Relative Error Between Simulation and Theory')\n",
    "    plt.grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('2d_random_walk_scaling.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    plt.figure(figsize=(10, 10))\n",
    "    \n",
    "    for i in range(5):\n",
    "        _, x_traj, y_traj = two_dimensional_random_walk(1000)\n",
    "        plt.plot(x_traj, y_traj, '-', alpha=0.7, label=f'Walk {i+1}')\n",
    "    \n",
    "    plt.xlabel('X Position')\n",
    "    plt.ylabel('Y Position')\n",
    "    plt.title('Sample Paths of 2D Random Walks')\n",
    "    plt.grid(True)\n",
    "    plt.axis('equal')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.savefig('2d_random_walk_paths.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "verify_scaling_law()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulating Diffusion-Limited Aggregation...\n",
      "Added 100 particles, cluster height: 195\n",
      "Added 200 particles, cluster height: 191\n",
      "Added 300 particles, cluster height: 187\n",
      "Added 400 particles, cluster height: 183\n",
      "Added 500 particles, cluster height: 181\n",
      "Added 600 particles, cluster height: 177\n",
      "Added 700 particles, cluster height: 176\n",
      "Added 800 particles, cluster height: 173\n",
      "Added 900 particles, cluster height: 168\n",
      "Added 1000 particles, cluster height: 165\n",
      "Added 1100 particles, cluster height: 160\n",
      "Added 1200 particles, cluster height: 157\n",
      "Added 1300 particles, cluster height: 156\n",
      "Added 1400 particles, cluster height: 151\n",
      "Added 1500 particles, cluster height: 143\n",
      "Added 1600 particles, cluster height: 139\n",
      "Added 1700 particles, cluster height: 133\n",
      "Added 1800 particles, cluster height: 130\n",
      "Added 1900 particles, cluster height: 127\n",
      "Added 2000 particles, cluster height: 123\n",
      "Added 2100 particles, cluster height: 117\n",
      "Added 2200 particles, cluster height: 113\n",
      "Added 2300 particles, cluster height: 110\n",
      "Added 2400 particles, cluster height: 107\n",
      "Added 2500 particles, cluster height: 103\n",
      "Added 2600 particles, cluster height: 99\n",
      "Added 2700 particles, cluster height: 92\n",
      "Added 2800 particles, cluster height: 87\n",
      "Added 2900 particles, cluster height: 79\n",
      "Added 3000 particles, cluster height: 72\n",
      "Added 3100 particles, cluster height: 65\n",
      "Added 3200 particles, cluster height: 58\n",
      "Added 3300 particles, cluster height: 44\n",
      "Added 3400 particles, cluster height: 23\n",
      "Added 3500 particles, cluster height: 15\n",
      "Added 3600 particles, cluster height: 5\n",
      "Added 3700 particles, cluster height: 1\n",
      "Added 3800 particles, cluster height: 0\n",
      "Added 3900 particles, cluster height: 0\n",
      "Added 4000 particles, cluster height: 0\n",
      "Added 4100 particles, cluster height: 0\n",
      "Added 4200 particles, cluster height: 0\n",
      "Added 4300 particles, cluster height: 0\n",
      "Added 4400 particles, cluster height: 0\n",
      "Added 4500 particles, cluster height: 0\n",
      "Added 4600 particles, cluster height: 0\n",
      "Added 4700 particles, cluster height: 0\n",
      "Added 4800 particles, cluster height: 0\n",
      "Added 4900 particles, cluster height: 0\n",
      "Added 5000 particles, cluster height: 0\n",
      "DLA simulation completed.\n"
     ]
    }
   ],
   "source": [
    "from matplotlib import colors\n",
    "\n",
    "def initialize_linear_seed(grid_size, seed_length):\n",
    "    grid = np.zeros(grid_size, dtype=int)\n",
    "    \n",
    "    start_pos = (grid_size[1] - seed_length) // 2\n",
    "    grid[-1, start_pos:start_pos + seed_length] = 1\n",
    "    \n",
    "    return grid\n",
    "\n",
    "def is_neighbor_to_cluster(grid, position):\n",
    "    row, col = position\n",
    "    height, width = grid.shape\n",
    "    \n",
    "    neighbors = [\n",
    "        (row-1, col),\n",
    "        (row+1, col),\n",
    "        (row, col-1),\n",
    "        (row, col+1)\n",
    "    ]\n",
    "    \n",
    "    for r, c in neighbors:\n",
    "        if 0 <= r < height and 0 <= c < width and grid[r, c] == 1:\n",
    "            return True\n",
    "    \n",
    "    return False\n",
    "\n",
    "def diffusion_limited_aggregation(grid_size=(200, 200), seed_length=100, num_particles=5000, max_distance=50):\n",
    "    grid = initialize_linear_seed(grid_size, seed_length)\n",
    "    \n",
    "    time_grid = np.zeros_like(grid)\n",
    "    \n",
    "    cluster_height = grid_size[0] - 1\n",
    "    \n",
    "    for t in range(1, num_particles + 1):\n",
    "        row = max(0, cluster_height - max_distance)\n",
    "        col = np.random.randint(0, grid_size[1])\n",
    "        \n",
    "        while True:\n",
    "            if is_neighbor_to_cluster(grid, (row, col)):\n",
    "                grid[row, col] = 1\n",
    "                time_grid[row, col] = t\n",
    "                \n",
    "                cluster_height = min(cluster_height, row)\n",
    "                break\n",
    "            \n",
    "            direction = np.random.randint(0, 4)\n",
    "            if direction == 0:\n",
    "                row = max(0, row - 1)\n",
    "            elif direction == 1:\n",
    "                row = min(grid_size[0] - 1, row + 1)\n",
    "            elif direction == 2:\n",
    "                col = max(0, col - 1)\n",
    "            else:\n",
    "                col = min(grid_size[1] - 1, col + 1)\n",
    "            \n",
    "            if row - cluster_height > max_distance:\n",
    "                row = max(0, cluster_height - np.random.randint(5, max_distance))\n",
    "                col = np.random.randint(0, grid_size[1])\n",
    "        \n",
    "        if t % 100 == 0:\n",
    "            print(f\"Added {t} particles, cluster height: {cluster_height}\")\n",
    "    \n",
    "    return grid, time_grid\n",
    "\n",
    "def visualize_dla_cluster(grid, time_grid, save_path='dla_cluster.png'):\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(grid, cmap='binary', origin='lower')\n",
    "    plt.title('Final DLA Cluster')\n",
    "    plt.colorbar(label='Cluster (1) / Empty (0)')\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    norm = colors.LogNorm(vmin=1, vmax=time_grid.max())\n",
    "    plt.imshow(time_grid, cmap='viridis', norm=norm, origin='lower')\n",
    "    plt.title('DLA Cluster Growth Timeline')\n",
    "    plt.colorbar(label='Particle Addition Order')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "print(\"Simulating Diffusion-Limited Aggregation...\")\n",
    "grid, time_grid = diffusion_limited_aggregation(seed_length=200)\n",
    "visualize_dla_cluster(grid, time_grid)\n",
    "print(\"DLA simulation completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulating DLA with Central Seed...\n",
      "Added 100 particles, cluster radius: 15.30\n",
      "Added 200 particles, cluster radius: 18.97\n",
      "Added 300 particles, cluster radius: 27.00\n",
      "Added 400 particles, cluster radius: 31.83\n",
      "Added 500 particles, cluster radius: 36.07\n",
      "Added 600 particles, cluster radius: 39.01\n",
      "Added 700 particles, cluster radius: 42.45\n",
      "Added 800 particles, cluster radius: 44.69\n",
      "Added 900 particles, cluster radius: 48.10\n",
      "Added 1000 particles, cluster radius: 50.33\n",
      "Added 1100 particles, cluster radius: 52.40\n",
      "Added 1200 particles, cluster radius: 54.56\n",
      "Added 1300 particles, cluster radius: 55.66\n",
      "Added 1400 particles, cluster radius: 59.14\n",
      "Added 1500 particles, cluster radius: 61.13\n",
      "Added 1600 particles, cluster radius: 65.00\n",
      "Added 1700 particles, cluster radius: 65.80\n",
      "Added 1800 particles, cluster radius: 68.01\n",
      "Added 1900 particles, cluster radius: 70.80\n",
      "Added 2000 particles, cluster radius: 74.89\n",
      "\n",
      "Analyzing boundary shape effects on DLA...\n",
      "Running DLA with circular boundary...\n",
      "Added 100 particles, cluster radius: 11.05\n",
      "Added 200 particles, cluster radius: 20.12\n",
      "Added 300 particles, cluster radius: 26.25\n",
      "Added 400 particles, cluster radius: 29.41\n",
      "Added 500 particles, cluster radius: 31.62\n",
      "Added 600 particles, cluster radius: 34.99\n",
      "Added 700 particles, cluster radius: 38.01\n",
      "Added 800 particles, cluster radius: 41.05\n",
      "Added 900 particles, cluster radius: 42.05\n",
      "Added 1000 particles, cluster radius: 43.05\n",
      "Added 1100 particles, cluster radius: 47.04\n",
      "Added 1200 particles, cluster radius: 49.04\n",
      "Added 1300 particles, cluster radius: 52.04\n",
      "Added 1400 particles, cluster radius: 52.04\n",
      "Added 1500 particles, cluster radius: 52.04\n",
      "Added 1600 particles, cluster radius: 55.36\n",
      "Added 1700 particles, cluster radius: 56.32\n",
      "Added 1800 particles, cluster radius: 56.92\n",
      "Added 1900 particles, cluster radius: 58.60\n",
      "Added 2000 particles, cluster radius: 60.03\n",
      "Added 2100 particles, cluster radius: 60.03\n",
      "Added 2200 particles, cluster radius: 61.85\n",
      "Added 2300 particles, cluster radius: 62.36\n",
      "Added 2400 particles, cluster radius: 63.32\n",
      "Added 2500 particles, cluster radius: 65.25\n",
      "Added 2600 particles, cluster radius: 66.22\n",
      "Added 2700 particles, cluster radius: 66.76\n",
      "Added 2800 particles, cluster radius: 66.76\n",
      "Added 2900 particles, cluster radius: 67.62\n",
      "Added 3000 particles, cluster radius: 68.54\n",
      "Added 3100 particles, cluster radius: 68.96\n",
      "Added 3200 particles, cluster radius: 70.94\n",
      "Added 3300 particles, cluster radius: 72.80\n",
      "Added 3400 particles, cluster radius: 73.16\n",
      "Added 3500 particles, cluster radius: 73.93\n",
      "Added 3600 particles, cluster radius: 74.85\n",
      "Added 3700 particles, cluster radius: 74.85\n",
      "Added 3800 particles, cluster radius: 75.00\n",
      "Added 3900 particles, cluster radius: 75.58\n",
      "Added 4000 particles, cluster radius: 78.00\n",
      "Added 4100 particles, cluster radius: 79.31\n",
      "Added 4200 particles, cluster radius: 79.48\n",
      "Added 4300 particles, cluster radius: 80.41\n",
      "Added 4400 particles, cluster radius: 81.34\n",
      "Added 4500 particles, cluster radius: 81.54\n",
      "Added 4600 particles, cluster radius: 83.22\n",
      "Added 4700 particles, cluster radius: 83.22\n",
      "Added 4800 particles, cluster radius: 83.22\n",
      "Added 4900 particles, cluster radius: 84.86\n",
      "Added 5000 particles, cluster radius: 85.80\n",
      "Running DLA with square boundary...\n",
      "Added 100 particles, cluster radius: 16.49\n",
      "Added 200 particles, cluster radius: 24.19\n",
      "Added 300 particles, cluster radius: 28.16\n",
      "Added 400 particles, cluster radius: 31.38\n",
      "Added 500 particles, cluster radius: 32.76\n",
      "Added 600 particles, cluster radius: 39.12\n",
      "Added 700 particles, cluster radius: 40.61\n",
      "Added 800 particles, cluster radius: 43.01\n",
      "Added 900 particles, cluster radius: 46.62\n",
      "Added 1000 particles, cluster radius: 48.01\n",
      "Added 1100 particles, cluster radius: 51.04\n",
      "Added 1200 particles, cluster radius: 54.38\n",
      "Added 1300 particles, cluster radius: 54.38\n",
      "Added 1400 particles, cluster radius: 55.47\n",
      "Added 1500 particles, cluster radius: 55.76\n",
      "Added 1600 particles, cluster radius: 57.20\n",
      "Added 1700 particles, cluster radius: 57.20\n",
      "Added 1800 particles, cluster radius: 58.01\n",
      "Added 1900 particles, cluster radius: 59.20\n",
      "Added 2000 particles, cluster radius: 60.00\n",
      "Added 2100 particles, cluster radius: 60.84\n",
      "Added 2200 particles, cluster radius: 61.74\n",
      "Added 2300 particles, cluster radius: 63.51\n",
      "Added 2400 particles, cluster radius: 65.31\n",
      "Added 2500 particles, cluster radius: 65.31\n",
      "Added 2600 particles, cluster radius: 66.21\n",
      "Added 2700 particles, cluster radius: 66.21\n",
      "Added 2800 particles, cluster radius: 67.12\n",
      "Added 2900 particles, cluster radius: 68.24\n",
      "Added 3000 particles, cluster radius: 69.89\n",
      "Added 3100 particles, cluster radius: 69.89\n",
      "Added 3200 particles, cluster radius: 70.68\n",
      "Added 3300 particles, cluster radius: 72.50\n",
      "Added 3400 particles, cluster radius: 72.50\n",
      "Added 3500 particles, cluster radius: 72.50\n",
      "Added 3600 particles, cluster radius: 72.50\n",
      "Added 3700 particles, cluster radius: 72.80\n",
      "Added 3800 particles, cluster radius: 73.01\n",
      "Added 3900 particles, cluster radius: 73.93\n",
      "Added 4000 particles, cluster radius: 73.93\n",
      "Added 4100 particles, cluster radius: 75.00\n",
      "Added 4200 particles, cluster radius: 75.61\n",
      "Added 4300 particles, cluster radius: 75.61\n",
      "Added 4400 particles, cluster radius: 76.55\n",
      "Added 4500 particles, cluster radius: 77.49\n",
      "Added 4600 particles, cluster radius: 77.49\n",
      "Added 4700 particles, cluster radius: 77.49\n",
      "Added 4800 particles, cluster radius: 77.49\n",
      "Added 4900 particles, cluster radius: 78.01\n",
      "Added 5000 particles, cluster radius: 79.81\n",
      "Estimated fractal dimension (circle): 1.596\n",
      "Estimated fractal dimension (square): 1.605\n",
      "Completed. Added 2000 particles.\n"
     ]
    }
   ],
   "source": [
    "def initialize_central_seed(grid_size):\n",
    "    grid = np.zeros(grid_size, dtype=int)\n",
    "    \n",
    "    center_row = grid_size[0] // 2\n",
    "    center_col = grid_size[1] // 2\n",
    "    grid[center_row, center_col] = 1\n",
    "    \n",
    "    return grid, (center_row, center_col)\n",
    "\n",
    "def place_particle_on_boundary(center, radius, grid_size, boundary_shape='circle'):\n",
    "    if boundary_shape == 'circle':\n",
    "        angle = 2 * np.pi * np.random.random()\n",
    "        \n",
    "        row = int(center[0] + radius * np.sin(angle))\n",
    "        col = int(center[1] + radius * np.cos(angle))\n",
    "    \n",
    "    elif boundary_shape == 'square':\n",
    "        side = np.random.randint(0, 4)\n",
    "        \n",
    "        if side == 0:\n",
    "            row = int(center[0] - radius)\n",
    "            col = int(center[1] - radius + 2 * radius * np.random.random())\n",
    "        elif side == 1:\n",
    "            row = int(center[0] - radius + 2 * radius * np.random.random())\n",
    "            col = int(center[1] + radius)\n",
    "        elif side == 2:\n",
    "            row = int(center[0] + radius)\n",
    "            col = int(center[1] - radius + 2 * radius * np.random.random())\n",
    "        else:\n",
    "            row = int(center[0] - radius + 2 * radius * np.random.random())\n",
    "            col = int(center[1] - radius)\n",
    "    \n",
    "    row = max(0, min(grid_size[0] - 1, row))\n",
    "    col = max(0, min(grid_size[1] - 1, col))\n",
    "    \n",
    "    return (row, col)\n",
    "\n",
    "def distance(pos1, pos2):\n",
    "    return math.sqrt((pos1[0] - pos2[0])**2 + (pos1[1] - pos2[1])**2)\n",
    "\n",
    "def dla_central_seed(grid_size=(400, 400), num_particles=5000, launch_radius_factor=1.5):\n",
    "    grid, center = initialize_central_seed(grid_size)\n",
    "    \n",
    "    time_grid = np.zeros_like(grid)\n",
    "    time_grid[center] = 1\n",
    "    \n",
    "    cluster_radius = 0\n",
    "    \n",
    "    for t in range(2, num_particles + 2):\n",
    "        launch_radius = max(5, cluster_radius * launch_radius_factor)\n",
    "        \n",
    "        row, col = place_particle_on_boundary(center, launch_radius, grid_size, 'circle')\n",
    "        \n",
    "        max_distance = launch_radius * 2\n",
    "        \n",
    "        while True:\n",
    "            if is_neighbor_to_cluster(grid, (row, col)):\n",
    "                grid[row, col] = 1\n",
    "                time_grid[row, col] = t\n",
    "                \n",
    "                new_radius = distance((row, col), center)\n",
    "                cluster_radius = max(cluster_radius, new_radius)\n",
    "                break\n",
    "            \n",
    "            direction = np.random.randint(0, 4)\n",
    "            if direction == 0:\n",
    "                row = max(0, row - 1)\n",
    "            elif direction == 1:\n",
    "                row = min(grid_size[0] - 1, row + 1)\n",
    "            elif direction == 2:\n",
    "                col = max(0, col - 1)\n",
    "            else:\n",
    "                col = min(grid_size[1] - 1, col + 1)\n",
    "            \n",
    "            if distance((row, col), center) > max_distance:\n",
    "                row, col = place_particle_on_boundary(center, launch_radius, grid_size, 'circle')\n",
    "        \n",
    "        if t % 100 == 0:\n",
    "            print(f\"Added {t} particles, cluster radius: {cluster_radius:.2f}\")\n",
    "    \n",
    "    return grid, time_grid, center\n",
    "\n",
    "def dla_with_boundary_analysis(grid_size=(400, 400), num_particles=5000, \n",
    "                              launch_radius_factor=1.5, boundary_shape='circle'):\n",
    "    grid, center = initialize_central_seed(grid_size)\n",
    "    \n",
    "    time_grid = np.zeros_like(grid)\n",
    "    time_grid[center] = 1\n",
    "    \n",
    "    growth_snapshots = {}\n",
    "    snapshot_points = [100, 500, 1000, 2000, 3000, 4000, 5000]\n",
    "    \n",
    "    cluster_radius = 0\n",
    "    \n",
    "    for t in range(2, num_particles + 2):\n",
    "        launch_radius = max(5, cluster_radius * launch_radius_factor)\n",
    "        \n",
    "        row, col = place_particle_on_boundary(center, launch_radius, grid_size, boundary_shape)\n",
    "        \n",
    "        max_distance = launch_radius * 2\n",
    "        \n",
    "        steps_taken = 0\n",
    "        max_steps = 10000\n",
    "        \n",
    "        while steps_taken < max_steps:\n",
    "            if is_neighbor_to_cluster(grid, (row, col)):\n",
    "                grid[row, col] = 1\n",
    "                time_grid[row, col] = t\n",
    "                \n",
    "                new_radius = distance((row, col), center)\n",
    "                cluster_radius = max(cluster_radius, new_radius)\n",
    "                break\n",
    "            \n",
    "            direction = np.random.randint(0, 4)\n",
    "            if direction == 0:\n",
    "                row = max(0, row - 1)\n",
    "            elif direction == 1:\n",
    "                row = min(grid_size[0] - 1, row + 1)\n",
    "            elif direction == 2:\n",
    "                col = max(0, col - 1)\n",
    "            else:\n",
    "                col = min(grid_size[1] - 1, col + 1)\n",
    "            \n",
    "            if distance((row, col), center) > max_distance:\n",
    "                row, col = place_particle_on_boundary(center, launch_radius, grid_size, boundary_shape)\n",
    "            \n",
    "            steps_taken += 1\n",
    "        \n",
    "        if t in snapshot_points:\n",
    "            growth_snapshots[t] = grid.copy()\n",
    "        \n",
    "        if t % 100 == 0:\n",
    "            print(f\"Added {t} particles, cluster radius: {cluster_radius:.2f}\")\n",
    "    \n",
    "    return grid, time_grid, center, growth_snapshots\n",
    "\n",
    "def visualize_central_dla(grid, time_grid, center, save_path='dla_central_seed.png'):\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(grid, cmap='binary')\n",
    "    plt.scatter(center[1], center[0], c='red', s=50)\n",
    "    plt.title('Final DLA Cluster with Central Seed')\n",
    "    plt.colorbar(label='Cluster (1) / Empty (0)')\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    norm = colors.LogNorm(vmin=1, vmax=time_grid.max())\n",
    "    plt.imshow(time_grid, cmap='viridis', norm=norm)\n",
    "    plt.title('DLA Cluster Growth Timeline')\n",
    "    plt.colorbar(label='Particle Addition Order')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    plt.figure(figsize=(12, 12))\n",
    "    plt.imshow(grid, cmap='binary')\n",
    "    plt.title('DLA Cluster with Central Seed')\n",
    "    plt.axis('off')\n",
    "    plt.savefig('dla_central_detailed.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "def analyze_cluster_properties(grid, center, boundary_shape=\"circle\"):\n",
    "    max_radius = min(grid.shape) // 2\n",
    "    \n",
    "    max_radius_for_analysis = 40\n",
    "    radius_step = 2\n",
    "    radius_values = np.arange(1, max_radius, radius_step)\n",
    "    \n",
    "    mass_values = []\n",
    "    \n",
    "    for r in radius_values:\n",
    "        mass = 0\n",
    "        for i in range(grid.shape[0]):\n",
    "            for j in range(grid.shape[1]):\n",
    "                if grid[i, j] == 1 and distance((i, j), center) <= r:\n",
    "                    mass += 1\n",
    "        mass_values.append(mass)\n",
    "    \n",
    "    analysis_mask = radius_values <= max_radius_for_analysis\n",
    "    radius_for_fit = radius_values[analysis_mask]\n",
    "    mass_for_fit = np.array(mass_values)[analysis_mask]\n",
    "    \n",
    "    log_radius = np.log(radius_for_fit)\n",
    "    log_mass = np.log(mass_for_fit)\n",
    "    \n",
    "    slope, intercept, r_value, p_value, std_err = stats.linregress(log_radius, log_mass)\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    \n",
    "    plt.loglog(radius_values, mass_values, 'bo', alpha=0.5, label='All data')\n",
    "    \n",
    "    plt.loglog(radius_for_fit, mass_for_fit, 'ro', label='Data used for fitting')\n",
    "    \n",
    "    fit_x = np.linspace(min(log_radius), max(log_radius), 100)\n",
    "    fit_y = intercept + slope * fit_x\n",
    "    plt.loglog(np.exp(fit_x), np.exp(fit_y), 'g-', \n",
    "              label=f'Fit: dimension ≈ {slope:.3f} (R² = {r_value**2:.3f})')\n",
    "    \n",
    "    plt.xlabel('Radius')\n",
    "    plt.ylabel('Mass (number of particles)')\n",
    "    plt.title(f'DLA Fractal Dimension Analysis - {boundary_shape.capitalize()} Boundary')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    \n",
    "    plt.annotate(f'Fitting limited to radius ≤ {max_radius_for_analysis} to avoid boundary effects', \n",
    "                xy=(0.5, 0.95), xycoords='figure fraction', \n",
    "                bbox=dict(boxstyle=\"round,pad=0.3\", fc=\"yellow\", alpha=0.3),\n",
    "                ha='center', va='top')\n",
    "    \n",
    "    plt.savefig(f'dla_fractal_dimension_{boundary_shape}.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    return {\n",
    "        'fractal_dimension': slope,\n",
    "        'r_squared': r_value**2,\n",
    "        'radii': radius_values,\n",
    "        'masses': mass_values,\n",
    "        'fit_limit': max_radius_for_analysis\n",
    "    }\n",
    "\n",
    "def analyze_boundary_effects():\n",
    "    print(\"\\nAnalyzing boundary shape effects on DLA...\")\n",
    "    \n",
    "    num_particles = 5000\n",
    "    grid_size = (400, 400)\n",
    "    \n",
    "    print(\"Running DLA with circular boundary...\")\n",
    "    circle_grid, circle_time_grid, circle_center, circle_snapshots = dla_with_boundary_analysis(\n",
    "        grid_size=grid_size, \n",
    "        num_particles=num_particles, \n",
    "        boundary_shape='circle'\n",
    "    )\n",
    "    \n",
    "    print(\"Running DLA with square boundary...\")\n",
    "    square_grid, square_time_grid, square_center, square_snapshots = dla_with_boundary_analysis(\n",
    "        grid_size=grid_size, \n",
    "        num_particles=num_particles, \n",
    "        boundary_shape='square'\n",
    "    )\n",
    "    \n",
    "    plt.figure(figsize=(15, 10))\n",
    "    \n",
    "    plt.subplot(2, 2, 1)\n",
    "    plt.imshow(circle_grid, cmap='binary')\n",
    "    plt.title('DLA with Circular Boundary')\n",
    "    plt.axis('off')\n",
    "    \n",
    "    plt.subplot(2, 2, 2)\n",
    "    plt.imshow(square_grid, cmap='binary')\n",
    "    plt.title('DLA with Square Boundary')\n",
    "    plt.axis('off')\n",
    "    \n",
    "    plt.subplot(2, 2, 3)\n",
    "    norm = colors.LogNorm(vmin=1, vmax=circle_time_grid.max())\n",
    "    plt.imshow(circle_time_grid, cmap='viridis', norm=norm)\n",
    "    plt.title('Growth Timeline (Circular Boundary)')\n",
    "    plt.colorbar(label='Particle Addition Order')\n",
    "    \n",
    "    plt.subplot(2, 2, 4)\n",
    "    norm = colors.LogNorm(vmin=1, vmax=square_time_grid.max())\n",
    "    plt.imshow(square_time_grid, cmap='viridis', norm=norm)\n",
    "    plt.title('Growth Timeline (Square Boundary)')\n",
    "    plt.colorbar(label='Particle Addition Order')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('dla_boundary_comparison.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    selected_snapshots = [1000, 3000, 5000]\n",
    "    \n",
    "    plt.figure(figsize=(15, 10))\n",
    "    for i, snapshot_point in enumerate(selected_snapshots):\n",
    "        plt.subplot(2, 3, i+1)\n",
    "        plt.imshow(circle_snapshots[snapshot_point], cmap='binary')\n",
    "        plt.title(f'Circle Boundary: {snapshot_point} particles')\n",
    "        plt.axis('off')\n",
    "        \n",
    "        plt.subplot(2, 3, i+4)\n",
    "        plt.imshow(square_snapshots[snapshot_point], cmap='binary')\n",
    "        plt.title(f'Square Boundary: {snapshot_point} particles')\n",
    "        plt.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('dla_growth_comparison.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    circle_dimensions = analyze_cluster_properties(circle_grid, circle_center, boundary_shape=\"circle\")\n",
    "    square_dimensions = analyze_cluster_properties(square_grid, square_center, boundary_shape=\"square\")\n",
    "    \n",
    "    print(f\"Estimated fractal dimension (circle): {circle_dimensions['fractal_dimension']:.3f}\")\n",
    "    print(f\"Estimated fractal dimension (square): {square_dimensions['fractal_dimension']:.3f}\")\n",
    "    \n",
    "    return {\n",
    "        'circle': {\n",
    "            'grid': circle_grid,\n",
    "            'time_grid': circle_time_grid,\n",
    "            'properties': circle_dimensions\n",
    "        },\n",
    "        'square': {\n",
    "            'grid': square_grid,\n",
    "            'time_grid': square_time_grid,\n",
    "            'properties': square_dimensions\n",
    "        }\n",
    "    }\n",
    "\n",
    "print(\"Simulating DLA with Central Seed...\")\n",
    "\n",
    "num_particles = 2000\n",
    "grid_size = (300, 300)\n",
    "\n",
    "grid, time_grid, center = dla_central_seed(grid_size=grid_size, num_particles=num_particles)\n",
    "visualize_central_dla(grid, time_grid, center)\n",
    "\n",
    "analyze_boundary_effects()\n",
    "\n",
    "print(f\"Completed. Added {num_particles} particles.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulating 5000 self-avoiding walks...\n",
      "Completed 1000/5000 walks. Time elapsed: 0.1s, Estimated remaining: 0.5s\n",
      "Completed 2000/5000 walks. Time elapsed: 0.2s, Estimated remaining: 0.3s\n",
      "Completed 3000/5000 walks. Time elapsed: 0.3s, Estimated remaining: 0.2s\n",
      "Completed 4000/5000 walks. Time elapsed: 0.4s, Estimated remaining: 0.1s\n",
      "Completed 5000/5000 walks. Time elapsed: 0.5s, Estimated remaining: 0.0s\n",
      "Analysis completed in 0.5 seconds.\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "import time\n",
    "\n",
    "def self_avoiding_random_walk(grid_size=100):\n",
    "    grid = np.zeros((grid_size, grid_size), dtype=bool)\n",
    "    \n",
    "    x, y = grid_size // 2, grid_size // 2\n",
    "    grid[x, y] = True\n",
    "    \n",
    "    x_traj = [x]\n",
    "    y_traj = [y]\n",
    "    \n",
    "    directions = [(0, 1), (0, -1), (1, 0), (-1, 0)]\n",
    "    \n",
    "    trapped = False\n",
    "    while not trapped:\n",
    "        available_moves = []\n",
    "        for dx, dy in directions:\n",
    "            nx, ny = x + dx, y + dy\n",
    "            if 0 <= nx < grid_size and 0 <= ny < grid_size and not grid[nx, ny]:\n",
    "                available_moves.append((nx, ny))\n",
    "        \n",
    "        if not available_moves:\n",
    "            trapped = True\n",
    "            break\n",
    "        \n",
    "        next_pos = available_moves[np.random.randint(0, len(available_moves))]\n",
    "        x, y = next_pos\n",
    "        \n",
    "        grid[x, y] = True\n",
    "        x_traj.append(x)\n",
    "        y_traj.append(y)\n",
    "    \n",
    "    return len(x_traj) - 1, x_traj, y_traj\n",
    "\n",
    "def analyze_self_avoiding_walks(num_walks=10000, grid_size=100):\n",
    "    print(f\"Simulating {num_walks} self-avoiding walks...\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    lengths = []\n",
    "    \n",
    "    for i in range(num_walks):\n",
    "        length, _, _ = self_avoiding_random_walk(grid_size)\n",
    "        lengths.append(length)\n",
    "        \n",
    "        if (i + 1) % 1000 == 0:\n",
    "            elapsed = time.time() - start_time\n",
    "            remaining = (elapsed / (i + 1)) * (num_walks - i - 1)\n",
    "            print(f\"Completed {i+1}/{num_walks} walks. Time elapsed: {elapsed:.1f}s, Estimated remaining: {remaining:.1f}s\")\n",
    "    \n",
    "    counter = Counter(lengths)\n",
    "    max_length = max(lengths)\n",
    "    distribution = [counter.get(i, 0) for i in range(max_length + 1)]\n",
    "    \n",
    "    probability_dist = [count / num_walks for count in distribution]\n",
    "    \n",
    "    print(f\"Analysis completed in {time.time() - start_time:.1f} seconds.\")\n",
    "    \n",
    "    return lengths, probability_dist\n",
    "\n",
    "def visualize_saw_results(lengths, probability_dist):\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    \n",
    "    plt.subplot(2, 2, 1)\n",
    "    plt.hist(lengths, bins=30, alpha=0.7, density=True)\n",
    "    plt.xlabel('Walk Length')\n",
    "    plt.ylabel('Probability Density')\n",
    "    plt.title('Distribution of Self-Avoiding Walk Lengths')\n",
    "    plt.grid(True)\n",
    "    \n",
    "    plt.subplot(2, 2, 2)\n",
    "    plt.bar(range(len(probability_dist)), probability_dist, alpha=0.7)\n",
    "    plt.xlabel('Walk Length')\n",
    "    plt.ylabel('Probability')\n",
    "    plt.title('Probability Distribution of Walk Lengths')\n",
    "    plt.grid(True)\n",
    "    \n",
    "    plt.subplot(2, 2, 3)\n",
    "    cumulative_dist = np.cumsum(probability_dist)\n",
    "    plt.plot(range(len(cumulative_dist)), cumulative_dist, 'bo-')\n",
    "    plt.xlabel('Walk Length')\n",
    "    plt.ylabel('Cumulative Probability')\n",
    "    plt.title('Cumulative Distribution of Walk Lengths')\n",
    "    plt.grid(True)\n",
    "    \n",
    "    plt.subplot(2, 2, 4)\n",
    "    \n",
    "    non_zero_indices = [i for i, p in enumerate(probability_dist) if p > 0]\n",
    "    x_values = [i for i in non_zero_indices]\n",
    "    y_values = [probability_dist[i] for i in non_zero_indices]\n",
    "    \n",
    "    plt.loglog(x_values, y_values, 'bo', alpha=0.7)\n",
    "    plt.xlabel('Walk Length (log)')\n",
    "    plt.ylabel('Probability (log)')\n",
    "    plt.title('Log-Log Plot of Walk Length Distribution')\n",
    "    plt.grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('saw_analysis.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    plt.figure(figsize=(15, 5))\n",
    "    \n",
    "    for i in range(3):\n",
    "        plt.subplot(1, 3, i+1)\n",
    "        length, x_traj, y_traj = self_avoiding_random_walk()\n",
    "        plt.plot(x_traj, y_traj, 'b-', alpha=0.7)\n",
    "        plt.plot(x_traj[0], y_traj[0], 'go', label='Start')\n",
    "        plt.plot(x_traj[-1], y_traj[-1], 'ro', label='End')\n",
    "        plt.title(f'Example SAW (Length = {length})')\n",
    "        plt.grid(True)\n",
    "        plt.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('saw_examples.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "lengths, probability_dist = analyze_self_avoiding_walks(num_walks=5000)\n",
    "visualize_saw_results(lengths, probability_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counting self-avoiding walks up to length 16...\n",
      "Enumeration completed in 9.08 seconds.\n",
      "\n",
      "Counts of self-avoiding walks vs random walks:\n",
      "Length | SAWs      | Random Walks | Ratio\n",
      "-------|-----------|--------------|---------\n",
      "     0 |         1 |            1 | 1.00000000\n",
      "     1 |         4 |            4 | 1.00000000\n",
      "     2 |        12 |           16 | 0.75000000\n",
      "     3 |        36 |           64 | 0.56250000\n",
      "     4 |       100 |          256 | 0.39062500\n",
      "     5 |       284 |         1024 | 0.27734375\n",
      "     6 |       780 |         4096 | 0.19042969\n",
      "     7 |      2172 |        16384 | 0.13256836\n",
      "     8 |      5916 |        65536 | 0.09027100\n",
      "     9 |     16268 |       262144 | 0.06205750\n",
      "    10 |     44100 |      1048576 | 0.04205704\n",
      "    11 |    120292 |      4194304 | 0.02867985\n",
      "    12 |    324932 |     16777216 | 0.01936746\n",
      "    13 |    881500 |     67108864 | 0.01313537\n",
      "    14 |   2374444 |    268435456 | 0.00884549\n",
      "    15 |   6416596 |   1073741824 | 0.00597592\n",
      "    16 |  17245332 |   4294967296 | 0.00401524\n",
      "Estimated SAW growth constant: 2.709538\n"
     ]
    }
   ],
   "source": [
    "def count_self_avoiding_walks(max_length):\n",
    "    grid_size = 2 * max_length + 1\n",
    "    \n",
    "    center = grid_size // 2\n",
    "    \n",
    "    counts = [0] * (max_length + 1)\n",
    "    counts[0] = 1\n",
    "    \n",
    "    visited = np.zeros((grid_size, grid_size), dtype=bool)\n",
    "    visited[center, center] = True\n",
    "    \n",
    "    directions = [(0, 1), (0, -1), (1, 0), (-1, 0)]\n",
    "    \n",
    "    def dfs(x, y, length):\n",
    "        if length == max_length:\n",
    "            return\n",
    "        \n",
    "        for dx, dy in directions:\n",
    "            nx, ny = x + dx, y + dy\n",
    "            \n",
    "            if 0 <= nx < grid_size and 0 <= ny < grid_size and not visited[nx, ny]:\n",
    "                visited[nx, ny] = True\n",
    "                \n",
    "                counts[length + 1] += 1\n",
    "                \n",
    "                dfs(nx, ny, length + 1)\n",
    "                \n",
    "                visited[nx, ny] = False\n",
    "    \n",
    "    dfs(center, center, 0)\n",
    "    \n",
    "    return counts\n",
    "\n",
    "def analyze_saw_growth(max_length=16):\n",
    "    print(f\"Counting self-avoiding walks up to length {max_length}...\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    saw_counts = count_self_avoiding_walks(max_length)\n",
    "    \n",
    "    elapsed = time.time() - start_time\n",
    "    print(f\"Enumeration completed in {elapsed:.2f} seconds.\")\n",
    "    \n",
    "    rw_counts = [4**n if n > 0 else 1 for n in range(max_length + 1)]\n",
    "    \n",
    "    ratios = [saw / rw if rw > 0 else 0 for saw, rw in zip(saw_counts, rw_counts)]\n",
    "    \n",
    "    print(\"\\nCounts of self-avoiding walks vs random walks:\")\n",
    "    print(\"Length | SAWs      | Random Walks | Ratio\")\n",
    "    print(\"-------|-----------|--------------|---------\")\n",
    "    for n in range(max_length + 1):\n",
    "        print(f\"{n:6d} | {saw_counts[n]:9d} | {rw_counts[n]:12d} | {ratios[n]:.8f}\")\n",
    "    \n",
    "    plt.figure(figsize=(15, 10))\n",
    "    \n",
    "    plt.subplot(2, 2, 1)\n",
    "    plt.semilogy(range(max_length + 1), saw_counts, 'bo-', label='Self-Avoiding Walks')\n",
    "    plt.semilogy(range(max_length + 1), rw_counts, 'ro-', label='Random Walks')\n",
    "    plt.xlabel('Walk Length')\n",
    "    plt.ylabel('Number of Walks (log scale)')\n",
    "    plt.title('Growth of Walk Counts')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    \n",
    "    plt.subplot(2, 2, 2)\n",
    "    plt.plot(range(max_length + 1), ratios, 'go-')\n",
    "    plt.xlabel('Walk Length')\n",
    "    plt.ylabel('Ratio (SAW/RW)')\n",
    "    plt.title('Ratio of Self-Avoiding to Random Walks')\n",
    "    plt.grid(True)\n",
    "    \n",
    "    lengths = np.array(range(max_length//2, max_length + 1))\n",
    "    log_saw_counts = np.log(saw_counts[max_length//2:])\n",
    "    \n",
    "    coeffs = np.polyfit(lengths, log_saw_counts, 1)\n",
    "    growth_constant = np.exp(coeffs[0])\n",
    "    \n",
    "    plt.subplot(2, 2, 3)\n",
    "    plt.plot(lengths, log_saw_counts, 'bo', label='Log(SAW counts)')\n",
    "    plt.plot(lengths, coeffs[0] * lengths + coeffs[1], 'r-', \n",
    "             label=f'Fit: growth constant ≈ {growth_constant:.4f}')\n",
    "    plt.xlabel('Walk Length')\n",
    "    plt.ylabel('Log(Number of Walks)')\n",
    "    plt.title('Estimating SAW Growth Constant')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('saw_enumeration.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    return saw_counts, rw_counts, ratios, growth_constant\n",
    "\n",
    "\n",
    "saw_counts, rw_counts, ratios, growth_constant = analyze_saw_growth(max_length=16)\n",
    "print(f\"Estimated SAW growth constant: {growth_constant:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulating walks with persistence = 0.0...\n",
      "Simulating walks with persistence = 0.3...\n",
      "Simulating walks with persistence = 0.7...\n",
      "Simulating walks with persistence = 0.9...\n"
     ]
    }
   ],
   "source": [
    "def persistent_random_walk(num_steps, persistence=0.7):\n",
    "    x, y = 0, 0\n",
    "    x_traj = [x]\n",
    "    y_traj = [y]\n",
    "    \n",
    "    directions = [(1, 0), (0, 1), (-1, 0), (0, -1)]\n",
    "    \n",
    "    current_dir_idx = np.random.randint(0, 4)\n",
    "    \n",
    "    for _ in range(num_steps):\n",
    "        if np.random.random() < persistence:\n",
    "            pass\n",
    "        else:\n",
    "            current_dir_idx = np.random.randint(0, 4)\n",
    "        \n",
    "        dx, dy = directions[current_dir_idx]\n",
    "        x += dx\n",
    "        y += dy\n",
    "        \n",
    "        x_traj.append(x)\n",
    "        y_traj.append(y)\n",
    "    \n",
    "    return x_traj, y_traj\n",
    "\n",
    "def analyze_persistence_effect(num_walks=1000, num_steps=1000, persistence_values=[0.0, 0.3, 0.7, 0.9]):\n",
    "    results = {}\n",
    "    \n",
    "    for p in persistence_values:\n",
    "        print(f\"Simulating walks with persistence = {p}...\")\n",
    "        \n",
    "        final_x = np.zeros(num_walks)\n",
    "        final_y = np.zeros(num_walks)\n",
    "        squared_displacements = np.zeros((num_walks, num_steps + 1))\n",
    "        \n",
    "        for i in range(num_walks):\n",
    "            x_traj, y_traj = persistent_random_walk(num_steps, p)\n",
    "            \n",
    "            final_x[i] = x_traj[-1]\n",
    "            final_y[i] = y_traj[-1]\n",
    "            \n",
    "            for t in range(num_steps + 1):\n",
    "                squared_displacements[i, t] = x_traj[t]**2 + y_traj[t]**2\n",
    "        \n",
    "        mean_squared_disp = np.mean(squared_displacements, axis=0)\n",
    "        std_error = np.std(squared_displacements, axis=0) / np.sqrt(num_walks)\n",
    "        \n",
    "        results[p] = {\n",
    "            'final_x': final_x,\n",
    "            'final_y': final_y,\n",
    "            'mean_squared_disp': mean_squared_disp,\n",
    "            'std_error': std_error\n",
    "        }\n",
    "    \n",
    "    return results\n",
    "\n",
    "def visualize_persistence_results(results, num_steps):\n",
    "    persistence_values = sorted(results.keys())\n",
    "    \n",
    "    plt.figure(figsize=(12, 8))\n",
    "    time_points = np.arange(0, num_steps + 1)\n",
    "    \n",
    "    for p in persistence_values:\n",
    "        msd = results[p]['mean_squared_disp']\n",
    "        error = results[p]['std_error']\n",
    "        plt.errorbar(time_points, msd, yerr=error, label=f'p = {p}', alpha=0.7, capsize=3)\n",
    "    \n",
    "    t_values = np.linspace(0, num_steps, 100)\n",
    "    plt.plot(t_values, t_values, 'k--', label='Normal diffusion (~t)')\n",
    "    \n",
    "    plt.xlabel('Time Steps')\n",
    "    plt.ylabel('Mean Squared Displacement')\n",
    "    plt.title('Effect of Persistence on Mean Squared Displacement')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.xscale('log')\n",
    "    plt.yscale('log')\n",
    "    \n",
    "    plt.savefig('persistent_walk_msd.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    plt.figure(figsize=(15, 10))\n",
    "    \n",
    "    for i, p in enumerate(persistence_values):\n",
    "        plt.subplot(2, 2, i+1)\n",
    "        plt.scatter(results[p]['final_x'], results[p]['final_y'], alpha=0.3, s=5)\n",
    "        plt.xlabel('X Position')\n",
    "        plt.ylabel('Y Position')\n",
    "        plt.title(f'Final Positions (p = {p})')\n",
    "        plt.grid(True)\n",
    "        plt.axis('equal')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('persistent_walk_positions.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    plt.figure(figsize=(15, 10))\n",
    "    \n",
    "    for i, p in enumerate(persistence_values):\n",
    "        plt.subplot(2, 2, i+1)\n",
    "        \n",
    "        for _ in range(3):\n",
    "            x_traj, y_traj = persistent_random_walk(num_steps, p)\n",
    "            plt.plot(x_traj, y_traj, alpha=0.7)\n",
    "        \n",
    "        plt.xlabel('X Position')\n",
    "        plt.ylabel('Y Position')\n",
    "        plt.title(f'Sample Paths (p = {p})')\n",
    "        plt.grid(True)\n",
    "        plt.axis('equal')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('persistent_walk_paths.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    persistence_lengths = []\n",
    "    for p in persistence_values:\n",
    "        if p == 0:\n",
    "            persistence_lengths.append(1)\n",
    "        else:\n",
    "            persistence_length = 1 / (1 - p)\n",
    "            persistence_lengths.append(persistence_length)\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(persistence_values, persistence_lengths, 'bo-')\n",
    "    plt.xlabel('Persistence Parameter')\n",
    "    plt.ylabel('Persistence Length')\n",
    "    plt.title('Relationship Between Persistence Parameter and Persistence Length')\n",
    "    plt.grid(True)\n",
    "    \n",
    "    plt.savefig('persistence_length.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "num_steps = 1000\n",
    "persistence_values = [0.0, 0.3, 0.7, 0.9]\n",
    "\n",
    "results = analyze_persistence_effect(num_walks=500, num_steps=num_steps, persistence_values=persistence_values)\n",
    "\n",
    "visualize_persistence_results(results, num_steps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulating Fixed Length random walk model...\n",
      "Simulating Gaussian random walk model...\n",
      "Simulating Exponential random walk model...\n",
      "Simulating Levy random walk model...\n"
     ]
    }
   ],
   "source": [
    "def continuous_random_walk(num_steps, step_length=1.0, variable_length=False, step_distribution=None):\n",
    "    x, y = 0, 0\n",
    "    x_traj = [x]\n",
    "    y_traj = [y]\n",
    "    \n",
    "    for _ in range(num_steps):\n",
    "        theta = 2 * np.pi * np.random.random()\n",
    "        \n",
    "        if variable_length:\n",
    "            if step_distribution == 'gaussian':\n",
    "                r = np.random.normal(0, step_length)\n",
    "            elif step_distribution == 'exponential':\n",
    "                r = np.random.exponential(step_length)\n",
    "            elif step_distribution == 'levy':\n",
    "                r = np.random.pareto(1.5) * step_length\n",
    "            else:\n",
    "                r = 2 * step_length * np.random.random()\n",
    "        else:\n",
    "            r = step_length\n",
    "        \n",
    "        x += r * np.cos(theta)\n",
    "        y += r * np.sin(theta)\n",
    "        \n",
    "        x_traj.append(x)\n",
    "        y_traj.append(y)\n",
    "    \n",
    "    return x_traj, y_traj\n",
    "\n",
    "def analyze_continuous_walks(num_walks=1000, num_steps=1000, models=[\n",
    "    {'name': 'Fixed Length', 'variable': False},\n",
    "    {'name': 'Gaussian', 'variable': True, 'distribution': 'gaussian'},\n",
    "    {'name': 'Exponential', 'variable': True, 'distribution': 'exponential'},\n",
    "    {'name': 'Levy', 'variable': True, 'distribution': 'levy'}\n",
    "]):\n",
    "    results = {}\n",
    "    \n",
    "    for model in models:\n",
    "        print(f\"Simulating {model['name']} random walk model...\")\n",
    "        \n",
    "        final_x = np.zeros(num_walks)\n",
    "        final_y = np.zeros(num_walks)\n",
    "        squared_displacements = np.zeros((num_walks, num_steps + 1))\n",
    "        \n",
    "        for i in range(num_walks):\n",
    "            x_traj, y_traj = continuous_random_walk(\n",
    "                num_steps, \n",
    "                variable_length=model.get('variable', False),\n",
    "                step_distribution=model.get('distribution', None)\n",
    "            )\n",
    "            \n",
    "            final_x[i] = x_traj[-1]\n",
    "            final_y[i] = y_traj[-1]\n",
    "            \n",
    "            for t in range(num_steps + 1):\n",
    "                squared_displacements[i, t] = x_traj[t]**2 + y_traj[t]**2\n",
    "        \n",
    "        mean_squared_disp = np.mean(squared_displacements, axis=0)\n",
    "        std_error = np.std(squared_displacements, axis=0) / np.sqrt(num_walks)\n",
    "        \n",
    "        results[model['name']] = {\n",
    "            'final_x': final_x,\n",
    "            'final_y': final_y,\n",
    "            'mean_squared_disp': mean_squared_disp,\n",
    "            'std_error': std_error\n",
    "        }\n",
    "    \n",
    "    return results\n",
    "\n",
    "def visualize_continuous_walk_results(results, num_steps):\n",
    "    model_names = list(results.keys())\n",
    "    \n",
    "    plt.figure(figsize=(12, 8))\n",
    "    time_points = np.arange(0, num_steps + 1)\n",
    "    \n",
    "    for model_name in model_names:\n",
    "        msd = results[model_name]['mean_squared_disp']\n",
    "        error = results[model_name]['std_error']\n",
    "        plt.errorbar(time_points[::50], msd[::50], yerr=error[::50], \n",
    "                     label=model_name, alpha=0.7, capsize=3)\n",
    "    \n",
    "    t_values = np.linspace(0, num_steps, 100)\n",
    "    plt.plot(t_values, t_values, 'k--', label='Normal diffusion (~t)')\n",
    "    \n",
    "    plt.xlabel('Time Steps')\n",
    "    plt.ylabel('Mean Squared Displacement')\n",
    "    plt.title('Mean Squared Displacement for Different Random Walk Models')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.xscale('log')\n",
    "    plt.yscale('log')\n",
    "    \n",
    "    plt.savefig('continuous_walk_msd.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    plt.figure(figsize=(15, 10))\n",
    "    \n",
    "    for i, model_name in enumerate(model_names):\n",
    "        plt.subplot(2, 2, i+1)\n",
    "        plt.scatter(results[model_name]['final_x'], results[model_name]['final_y'], \n",
    "                   alpha=0.3, s=5)\n",
    "        plt.xlabel('X Position')\n",
    "        plt.ylabel('Y Position')\n",
    "        plt.title(f'Final Positions ({model_name})')\n",
    "        plt.grid(True)\n",
    "        plt.axis('equal')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('continuous_walk_positions.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    plt.figure(figsize=(15, 10))\n",
    "    \n",
    "    for i, model_name in enumerate(model_names):\n",
    "        plt.subplot(2, 2, i+1)\n",
    "        \n",
    "        for _ in range(3):\n",
    "            x_traj, y_traj = continuous_random_walk(\n",
    "                num_steps,\n",
    "                variable_length=('Fixed' not in model_name),\n",
    "                step_distribution=model_name.lower() if 'Fixed' not in model_name else None\n",
    "            )\n",
    "            plt.plot(x_traj, y_traj, alpha=0.7)\n",
    "        \n",
    "        plt.xlabel('X Position')\n",
    "        plt.ylabel('Y Position')\n",
    "        plt.title(f'Sample Paths ({model_name})')\n",
    "        plt.grid(True)\n",
    "        plt.axis('equal')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('continuous_walk_paths.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    scaling_exponents = {}\n",
    "    for model_name in model_names:\n",
    "        msd = results[model_name]['mean_squared_disp']\n",
    "        mid_point = len(time_points) // 2\n",
    "        log_time = np.log(time_points[mid_point:])\n",
    "        log_msd = np.log(msd[mid_point:])\n",
    "        \n",
    "        slope, _, _, _, _ = stats.linregress(log_time, log_msd)\n",
    "        scaling_exponents[model_name] = slope\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.bar(model_names, [scaling_exponents[model] for model in model_names])\n",
    "    plt.axhline(y=1.0, linestyle='--', color='r', label='Normal diffusion (α=1)')\n",
    "    plt.xlabel('Random Walk Model')\n",
    "    plt.ylabel('Scaling Exponent α')\n",
    "    plt.title('Scaling Exponents for Different Random Walk Models')\n",
    "    plt.legend()\n",
    "    plt.grid(True, axis='y')\n",
    "    \n",
    "    plt.savefig('continuous_walk_scaling.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "num_steps = 10000\n",
    "\n",
    "results = analyze_continuous_walks(num_walks=10000, num_steps=num_steps)\n",
    "\n",
    "visualize_continuous_walk_results(results, num_steps)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
